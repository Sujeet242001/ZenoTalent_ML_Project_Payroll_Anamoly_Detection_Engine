{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217ac3da-0a64-49af-a22f-d99001fd1045",
   "metadata": {},
   "source": [
    "# ZENVY – AI Powered Payroll\n",
    "### Payroll Anomaly Detection Engine (Unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe8f06-4b25-4c23-b1a4-214833ec66e0",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6b810d-9e4e-40f0-9e46-0aee2845b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cec3ed-ce0f-4aca-b7be-b6564a7d7cde",
   "metadata": {},
   "source": [
    "### 2. Load Payroll CSV (Batch Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46b573e-5cc1-41af-8ca9-e4c238c5cd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>base_salary</th>\n",
       "      <th>overtime_hours</th>\n",
       "      <th>overtime_pay</th>\n",
       "      <th>working_days</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>43973</td>\n",
       "      <td>11</td>\n",
       "      <td>2773</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>38893</td>\n",
       "      <td>11</td>\n",
       "      <td>3367</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>45181</td>\n",
       "      <td>5</td>\n",
       "      <td>3913</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>52184</td>\n",
       "      <td>7</td>\n",
       "      <td>2196</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>38126</td>\n",
       "      <td>7</td>\n",
       "      <td>4492</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  base_salary  overtime_hours  overtime_pay  working_days  \\\n",
       "0         1001        43973              11          2773            20   \n",
       "1         1002        38893              11          3367            22   \n",
       "2         1003        45181               5          3913            22   \n",
       "3         1004        52184               7          2196            20   \n",
       "4         1005        38126               7          4492            22   \n",
       "\n",
       "   department_id  \n",
       "0              2  \n",
       "1              1  \n",
       "2              1  \n",
       "3              4  \n",
       "4              4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"payroll_anomaly_data.csv\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2b1be2-2a17-4068-8b15-3d8b249af217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   employee_id     500 non-null    int64\n",
      " 1   base_salary     500 non-null    int64\n",
      " 2   overtime_hours  500 non-null    int64\n",
      " 3   overtime_pay    500 non-null    int64\n",
      " 4   working_days    500 non-null    int64\n",
      " 5   department_id   500 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e346c5-bee2-4ec0-8204-598279b943bc",
   "metadata": {},
   "source": [
    "### 3. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e9430d2-a274-4392-9e99-b32d3ae0ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative salaries: 0\n",
      "Negative overtime pay: 1\n",
      "Negative overtime hours: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative salaries:\", (df[\"base_salary\"] <= 0).sum())\n",
    "print(\"Negative overtime pay:\", (df[\"overtime_pay\"] < 0).sum())\n",
    "print(\"Negative overtime hours:\", (df[\"overtime_hours\"] < 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0a298-8296-4938-8598-75fe4f8181bf",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering\n",
    "\n",
    "### (Detect Salary Manipulation & Fake Overtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9212d55-c133-4bb3-bbc9-4d8cb699a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    data = df.copy()\n",
    "\n",
    "    # Overtime ratios\n",
    "    data[\"ot_pay_ratio\"] = data[\"overtime_pay\"] / (data[\"base_salary\"] + 1)\n",
    "    data[\"ot_hours_ratio\"] = data[\"overtime_hours\"] / (data[\"working_days\"] + 1)\n",
    "\n",
    "    # Salary deviation vs department\n",
    "    dept_avg_salary = data.groupby(\"department_id\")[\"base_salary\"].transform(\"mean\")\n",
    "    data[\"salary_vs_dept_avg\"] = (\n",
    "        data[\"base_salary\"] - dept_avg_salary\n",
    "    ) / (dept_avg_salary + 1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ce0cf4b-c37b-48e6-96d5-eaa3d1870cb6",
   "metadata": {},
   "source": [
    "Why this works:\n",
    "    * Salary fraud → salary deviates from department norm\n",
    "\n",
    "    * Fake OT → abnormal OT hours or OT pay ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ea8ac-15ee-4c07-a1da-ac510c7e92c0",
   "metadata": {},
   "source": [
    "### 5. Salary Anomaly Detection (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "664ca422-72c8-4276-99bc-e01cf2ed8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_salary_anomalies(df, contamination=0.05):\n",
    "    features = [\"base_salary\", \"salary_vs_dept_avg\"]\n",
    "\n",
    "    X = df[features].fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    preds = model.fit_predict(X_scaled)\n",
    "    scores = model.score_samples(X_scaled)\n",
    "\n",
    "    return preds, scores, model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e58892-3d77-4b65-9a3a-3d35754d2086",
   "metadata": {},
   "source": [
    "### 6. Overtime Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9afe6343-5c44-4805-8b3f-e719d28f2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_overtime_anomalies(df, contamination=0.05):\n",
    "    features = [\n",
    "        \"overtime_hours\",\n",
    "        \"overtime_pay\",\n",
    "        \"ot_pay_ratio\",\n",
    "        \"ot_hours_ratio\"\n",
    "    ]\n",
    "\n",
    "    X = df[features].fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    preds = model.fit_predict(X_scaled)\n",
    "    scores = model.score_samples(X_scaled)\n",
    "\n",
    "    return preds, scores, model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c621db19-8061-4c87-99f7-18aaefc8e693",
   "metadata": {},
   "source": [
    "### 8. Combined Anomaly Detection (Salary + Overtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71f09ced-a3f1-4684-be4f-ac4be4f0cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_combined_anomalies(df, contamination=0.05):\n",
    "\n",
    "    numeric_features = [\n",
    "        \"base_salary\",\n",
    "        \"overtime_hours\",\n",
    "        \"overtime_pay\",\n",
    "        \"working_days\",\n",
    "        \"ot_pay_ratio\",\n",
    "        \"ot_hours_ratio\",\n",
    "        \"salary_vs_dept_avg\"\n",
    "    ]\n",
    "\n",
    "    categorical_features = [\"department_id\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler())\n",
    "            ]), numeric_features),\n",
    "\n",
    "            (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"),\n",
    "             categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X = df[numeric_features + categorical_features]\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    model = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    preds = model.fit_predict(X_transformed)\n",
    "    scores = model.score_samples(X_transformed)\n",
    "\n",
    "    return preds, scores, model, preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2624de1-7ae8-495d-bde9-c8ec70749fde",
   "metadata": {},
   "source": [
    "### 8. Concept Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a73c4701-1e97-4adc-b4b9-7d5fa5262512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_concept_drift(old_df, new_df):\n",
    "    features = [\"base_salary\", \"overtime_hours\"]\n",
    "\n",
    "    drift_report = []\n",
    "\n",
    "    for f in features:\n",
    "        mean_shift = abs(new_df[f].mean() - old_df[f].mean()) / (old_df[f].mean() + 1)\n",
    "        std_shift = abs(new_df[f].std() - old_df[f].std()) / (old_df[f].std() + 1)\n",
    "\n",
    "        if mean_shift > 0.15 or std_shift > 0.25:\n",
    "            drift_report.append({\n",
    "                \"feature\": f,\n",
    "                \"mean_shift\": mean_shift,\n",
    "                \"std_shift\": std_shift\n",
    "            })\n",
    "\n",
    "    return drift_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718dc3d-af53-477d-b874-07beca25bf4e",
   "metadata": {},
   "source": [
    "### 9. Real-Time Payroll Record Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3d7516-ea3d-470f-ad6a-cf064b7099d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_realtime_record(record, salary_model, ot_model,\n",
    "                            salary_scaler, ot_scaler, ref_df):\n",
    "\n",
    "    dept_avg = ref_df[\n",
    "        ref_df[\"department_id\"] == record[\"department_id\"]\n",
    "    ][\"base_salary\"].mean()\n",
    "\n",
    "    salary_vs_dept = (record[\"base_salary\"] - dept_avg) / (dept_avg + 1)\n",
    "\n",
    "    sal_X = salary_scaler.transform([[record[\"base_salary\"], salary_vs_dept]])\n",
    "    salary_flag = salary_model.predict(sal_X)[0] == -1\n",
    "\n",
    "    ot_ratio = record[\"overtime_pay\"] / (record[\"base_salary\"] + 1)\n",
    "    ot_hours_ratio = record[\"overtime_hours\"] / (record[\"working_days\"] + 1)\n",
    "\n",
    "    ot_X = ot_scaler.transform([[\n",
    "        record[\"overtime_hours\"],\n",
    "        record[\"overtime_pay\"],\n",
    "        ot_ratio,\n",
    "        ot_hours_ratio\n",
    "    ]])\n",
    "\n",
    "    ot_flag = ot_model.predict(ot_X)[0] == -1\n",
    "\n",
    "    return {\n",
    "        \"salary_anomaly\": salary_flag,\n",
    "        \"overtime_anomaly\": ot_flag\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e09209-b955-4a7a-a444-7212ce1bbaed",
   "metadata": {},
   "source": [
    "### 10. Main Execution (Batch + Real-Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "511e1a4d-fece-4c5c-b295-68cfb56f9b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 500\n",
      "Salary anomalies: 25\n",
      "Overtime anomalies: 25\n",
      "Combined anomalies: 25\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    processed_df = engineer_features(df)\n",
    "\n",
    "    sal_p, _, sal_model, sal_scaler = detect_salary_anomalies(processed_df)\n",
    "    ot_p, _, ot_model, ot_scaler = detect_overtime_anomalies(processed_df)\n",
    "    comb_p, _, _, _ = detect_combined_anomalies(processed_df)\n",
    "\n",
    "    processed_df[\"salary_anomaly\"] = sal_p == -1\n",
    "    processed_df[\"overtime_anomaly\"] = ot_p == -1\n",
    "    processed_df[\"combined_anomaly\"] = comb_p == -1\n",
    "\n",
    "    print(\"Total records:\", len(processed_df))\n",
    "    print(\"Salary anomalies:\", processed_df[\"salary_anomaly\"].sum())\n",
    "    print(\"Overtime anomalies:\", processed_df[\"overtime_anomaly\"].sum())\n",
    "    print(\"Combined anomalies:\", processed_df[\"combined_anomaly\"].sum())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7c5db-6fd0-4360-a5c3-21141cc87e2c",
   "metadata": {},
   "source": [
    "### 11. Algorithm Selection Rationale\n",
    "\n",
    "#### Isolation Forest\n",
    "\n",
    "    - No labels required\n",
    "\n",
    "    - Efficient for payroll-scale data\n",
    "\n",
    "    - Naturally isolates extreme behavior\n",
    "\n",
    "    - Robust to evolving payroll patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894beed-f1c6-4f4e-84e3-0f19820bd5a6",
   "metadata": {},
   "source": [
    "### 12. Evaluation Strategy (No Labels)\n",
    "\n",
    "    - Fixed contamination rate (5%)\n",
    "\n",
    "    - Review lowest anomaly scores\n",
    "\n",
    "    - Cross-check salary-only vs OT-only vs combined\n",
    "\n",
    "    - Human review of flagged records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee049c-5bd0-46ba-9d0a-112635b3d936",
   "metadata": {},
   "source": [
    "### 13. Deployment Plan\n",
    "\n",
    "    - Daily batch payroll scans\n",
    "\n",
    "    - Real-time API for new payroll entries\n",
    "\n",
    "    - Weekly drift monitoring\n",
    "\n",
    "    - Monthly retraining or drift-triggered retraining\n",
    "\n",
    "    - Audit dashboard for flagged employees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e752f-97a5-4b69-8aa7-b0b6e6cac8b0",
   "metadata": {},
   "source": [
    "# 1️⃣ PSEUDOCODE (Intern-Level, Clear & Structured)\n",
    "### Payroll Anomaly Detection Engine (Unsupervised)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94b064b7-ee40-4ddd-bd6a-3b5ca7f9cf3e",
   "metadata": {},
   "source": [
    "INPUT: Payroll CSV data\n",
    "\n",
    "STEP 1: Load payroll dataset\n",
    "\n",
    "STEP 2: Feature Engineering\n",
    "    - Compute overtime_pay_ratio\n",
    "    - Compute overtime_hours_ratio\n",
    "    - Compute salary deviation from department average\n",
    "\n",
    "STEP 3: Salary Anomaly Detection\n",
    "    - Select salary-related features\n",
    "    - Standardize features\n",
    "    - Train Isolation Forest\n",
    "    - Flag records with anomaly score = -1\n",
    "\n",
    "STEP 4: Overtime Anomaly Detection\n",
    "    - Select overtime-related features\n",
    "    - Standardize features\n",
    "    - Train Isolation Forest\n",
    "    - Flag abnormal overtime patterns\n",
    "\n",
    "STEP 5: Combined Anomaly Detection\n",
    "    - Combine salary + overtime features\n",
    "    - Encode department information\n",
    "    - Train Isolation Forest\n",
    "    - Detect complex fraud patterns\n",
    "\n",
    "STEP 6: Concept Drift Detection\n",
    "    - Compare historical vs recent payroll distributions\n",
    "    - Detect significant mean or variance shifts\n",
    "    - Trigger model retraining if drift detected\n",
    "\n",
    "STEP 7: Batch Pipeline\n",
    "    - Run anomaly detection daily on payroll data\n",
    "    - Store flagged records for audit\n",
    "\n",
    "STEP 8: Real-Time Pipeline\n",
    "    - Accept single payroll record\n",
    "    - Compute features\n",
    "    - Apply trained models\n",
    "    - Return anomaly flags\n",
    "\n",
    "OUTPUT:\n",
    "    - Salary anomaly flag\n",
    "    - Overtime anomaly flag\n",
    "    - Combined anomaly flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8022e2-513c-4163-94aa-4fe1ac4cd893",
   "metadata": {},
   "source": [
    "# 2️⃣ ALGORITHM SELECTION RATIONALE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a47e33-4827-492a-ac38-efd96e3b9f8e",
   "metadata": {},
   "source": [
    "### Why Isolation Forest?\n",
    "\n",
    "    - Payroll fraud data is unlabeled\n",
    "\n",
    "    - Isolation Forest:\n",
    "\n",
    "        - Works with unsupervised learning\n",
    "\n",
    "        - Efficient for large payroll datasets\n",
    "\n",
    "        - Naturally isolates rare, abnormal behavior\n",
    "\n",
    "        - Robust to changing payroll patterns\n",
    "\n",
    "    - Suitable for both batch and real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978b1ab-4548-436b-8bea-45c09a1df6a3",
   "metadata": {},
   "source": [
    "# 3️⃣ EVALUATION STRATEGY (NO LABELS)\n",
    "\n",
    "### Since fraud labels are unavailable:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed325ad0-d025-4e5e-9dfa-e9cec4344b84",
   "metadata": {},
   "source": [
    "#### Evaluation Techniques Used\n",
    "\n",
    "    - Fixed contamination rate (e.g., 5%)\n",
    "\n",
    "    - Rank records by anomaly score\n",
    "\n",
    "    - Manual audit of top anomalies\n",
    "\n",
    "    - Compare:\n",
    "        -Salary-only anomalies\n",
    "\n",
    "        -Overtime-only anomalies\n",
    "\n",
    "        -Combined anomalies\n",
    "\n",
    "    - Monitor anomaly rate stability over time\n",
    "\n",
    "#### Success Criteria\n",
    "\n",
    "    - Stable anomaly rate\n",
    "\n",
    "    - Business-explainable anomalies\n",
    "\n",
    "    - Reduced false positives after retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d8731-840a-4322-955e-212eb434b5e2",
   "metadata": {},
   "source": [
    "# 4️⃣ DEPLOYMENT PLAN (Production-Ready)\n",
    "### Architecture Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "081230bd-1124-42d6-ac10-c616827528f3",
   "metadata": {},
   "source": [
    "Payroll DB / CSV\n",
    "        |\n",
    "        v\n",
    "Batch Processor (Daily)\n",
    "        |\n",
    "Isolation Forest Models\n",
    "        |\n",
    "Anomaly Flags\n",
    "        |\n",
    "Audit Dashboard / Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d13960-eab4-4ae0-9756-4672e3b6ce42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
